{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Author**\n",
    "Shivansh Gupta"
   ],
   "id": "f5482ad272e8f41b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Importing All the Modules**\n",
    "\n",
    "- **`YOLO` (from `ultralytics`)**\n",
    "  - Load and run the **YOLOv8 model**.\n",
    "\n",
    "- **`cv2`**\n",
    "  - Read/write images.\n",
    "  - Draw bounding boxes and other shapes.\n",
    "  - Perform color space conversions (e.g., BGR â†” RGB).\n",
    "\n",
    "- **`numpy as np`**\n",
    "  - Work with image arrays.\n",
    "  - Perform numeric and matrix operations efficiently.\n",
    "\n",
    "- **`typing.List` / `typing.Dict`**\n",
    "  - Add **type annotations** for better code clarity and readability.\n",
    "\n",
    "- **`torch`**\n",
    "  - Detect GPU availability using `torch.cuda.is_available()`.\n",
    "  - Perform tensor operations if needed.\n",
    "\n",
    "- **`os`**\n",
    "  - Read environment variables.\n",
    "  - Check file paths and manage the filesystem."
   ],
   "id": "3f8fe2d6e80e0435"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.179757Z",
     "start_time": "2025-09-27T11:34:15.173079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import torch"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading Environment Variables\n",
    "\n",
    "```python\n",
    "# Load environment variables from a .env file\n"
   ],
   "id": "5003ceafa8dd77bc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.245079Z",
     "start_time": "2025-09-27T11:34:15.212817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"D:\\PycharmProjects\\Eco_Vision\\Backend\\.env\")"
   ],
   "id": "2fc2c6d3bcc58c95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6712\\2373333911.py:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  load_dotenv(dotenv_path=\"D:\\PycharmProjects\\Eco_Vision\\Backend\\.env\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### YOLO Model Setup\n",
    "\n",
    "- **Device Selection:**\n",
    "  You can **force the use of CPU or GPU** manually.\n",
    "  If not specified, the device will be **auto-detected** later.\n",
    "\n",
    "- **Model Path (`model_path`):**\n",
    "  - Uses the environment variable `MODEL_PATH` if it exists.\n",
    "  - Otherwise, defaults to `\"yolov8n.pt\"`.\n",
    "\n",
    "- **`YOLO(model_path)`**:\n",
    "  - Calls the **YOLO class** from Ultralytics with the given `model_path`.\n",
    "  - Loads the **pretrained model into memory**.\n",
    "  - **Important:** The model is loaded **once in the constructor**, so you **donâ€™t need to reload it** every time you perform detection.\n"
   ],
   "id": "ccd65e4d440f98c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.449586Z",
     "start_time": "2025-09-27T11:34:15.274432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.getenv(\"MODEL_PATH\",None) #if we didn't set model , default this come \"yolo12n.pt\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(model_path)"
   ],
   "id": "8600596ecb2f6898",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### As here  below we can see our model is lock & loaded on cpu not gpu as i dont have didicated graphic card ðŸ’€.",
   "id": "385e0a33dc2be99a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.469124Z",
     "start_time": "2025-09-27T11:34:15.462884Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"[YOLODetector] Loaded model: {model_path} on {device}\")",
   "id": "80079dd8ff0c20f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[YOLODetector] Loaded model: yolo12n.pt on cpu\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **COCO 2017 Dataset Classes**\n",
    "\n",
    "- These are the object classes we will use from the **COCO 2017 dataset**.\n",
    "- The model will detect only on these classes.\n",
    "\n",
    "> **Note:** COCO 2017 has 80 classes in total, but for our task, we select a subset relevant to our need.\n",
    "\n",
    "- When a detection is made:\n",
    "  - If the **class ID** is **in** `self.reusable_classes` â†’ âœ… keep it.\n",
    "  - If the **class ID** is **not in** `self.reusable_classes` â†’ âŒ ignore it.\n",
    "\n",
    "\n",
    "This keeps the detection system **focused only on relevant items**, reducing noise from unnecessary classes.\n"
   ],
   "id": "878411499563a814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.519851Z",
     "start_time": "2025-09-27T11:34:15.513957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reusable_classes = {\n",
    "    39: 'bottle',\n",
    "    41: 'cup',\n",
    "    42: 'fork',\n",
    "    43: 'knife',\n",
    "    44: 'spoon',\n",
    "    45: 'bowl',\n",
    "    46: 'banana',\n",
    "    47: 'apple',\n",
    "    51: 'orange',\n",
    "    67: 'cell phone',\n",
    "    73: 'laptop',\n",
    "    76: 'keyboard',\n",
    "    84: 'book',\n",
    "}"
   ],
   "id": "57a383b053fbd35c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Model Inference**\n",
    "\n",
    "- This is where the **actual inference happens**.\n",
    "- The input image/frame is passed to the YOLO model.\n",
    "- The model runs its **forward pass** and returns detections:\n",
    "  - **Bounding boxes** (location of objects).\n",
    "  - **Class IDs** (what the object is).\n",
    "  - **Confidence scores** (how sure the model is).\n",
    "\n",
    "> **Note:** Inference = the stage where the trained model is **applied to new data** to make predictions."
   ],
   "id": "21dacc1d11813ba1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:15.569578Z",
     "start_time": "2025-09-27T11:34:15.561053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def detect_objects(image_path: str, conf: float = 0.5, imgsz: int = 640) -> List[Dict]:\n",
    "    if not os.path.exists(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    classes = list(reusable_classes.keys())   #Gets all the keys (class IDs like 39, 41, 42, â€¦) from the reusable classes dictionary and make a list.\n",
    "    results = model(\n",
    "    image_path,\n",
    "    conf=conf,\n",
    "    imgsz=imgsz,\n",
    "    device=device,\n",
    "    classes=classes\n",
    ")\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        if not getattr(result, \"boxes\", None):\n",
    "            continue\n",
    "        for box in result.boxes:\n",
    "            class_id = int(box.cls[0])  #Itâ€™s a tensor (because YOLO is built on PyTorch)\n",
    "            confidence = float(box.conf[0])\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            detections.append({\n",
    "                    \"class_id\": class_id,\n",
    "                    \"class_name\": reusable_classes[class_id],\n",
    "                    \"confidence\": {\n",
    "                        \"score\": round(confidence, 4),       # raw score (0..1)\n",
    "                        \"percent\": round(confidence * 100, 1)  # human-friendly %\n",
    "                    },\n",
    "                    \"bbox\": [x1, y1, x2, y2]\n",
    "                })\n",
    "    return detections"
   ],
   "id": "3e6cb4bd2eb76971",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "results is a list of Result objects (one per input image). Each contains detected boxes, class IDs, confidences, etc.",
   "id": "e249816aa930e3e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **YOLO Inference Output (Ultralytics)**\n",
    "\n",
    "When we run inference, **Ultralytics YOLO** returns a **list of `Results` objects**\n",
    "ðŸ‘‰ one `Results` object **per input image**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 1: What is a `Results` object?**\n",
    "Each `Results` object contains:\n",
    "- The **input image** (possibly resized).\n",
    "- All **detections** found in that image.\n",
    "- **Helper methods** (e.g., `.plot()`, `.save()`).\n",
    "\n",
    "âž¡ï¸ In short: **`result` = container for one imageâ€™s predictions**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 2: What is `.boxes` inside a result?**\n",
    "- `result.boxes` â†’ an attribute of the `Results` object.\n",
    "- It is a **`Boxes` object** (Ultralyticsâ€™ custom class).\n",
    "- Stores **all bounding boxes YOLO predicted** for that image.\n",
    "- Each entry in `result.boxes` = **one detection**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Step 3: What does each box contain?**\n",
    "A single box has:\n",
    "- `.cls` â†’ predicted **class id** (e.g., `tensor([39.])`).\n",
    "- `.conf` â†’ **confidence score** (e.g., `tensor([0.872])`).\n",
    "- `.xyxy` â†’ bounding box in **[x1, y1, x2, y2]** format (absolute pixel values).\n",
    "- `.xywh` â†’ bounding box in **[x_center, y_center, width, height]** format.\n",
    "- `.data` â†’ raw tensor with all values stacked.\n",
    "\n",
    "---\n",
    "\n",
    "âœ… Example:\n",
    "If YOLO finds **3 objects** in an image, then `result.boxes` will contain **3 box objects**,\n",
    "each with its own class, confidence, and coordinates."
   ],
   "id": "d4b3cc836a774833"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### **Lets run & see how this works**",
   "id": "daa98e3e7538a0bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:16.141538Z",
     "start_time": "2025-09-27T11:34:15.583795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detect = detect_objects(\"test.jpg\")\n",
    "print(detect)"
   ],
   "id": "e31218980c1c7691",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\PycharmProjects\\Eco_Vision\\Backend\\ML notebook\\test.jpg: 576x640 8 bottles, 266.7ms\n",
      "Speed: 64.9ms preprocess, 266.7ms inference, 21.5ms postprocess per image at shape (1, 3, 576, 640)\n",
      "[{'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.9479, 'percent': 94.8}, 'bbox': [190, 67, 222, 181]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.7831, 'percent': 78.3}, 'bbox': [26, 62, 51, 155]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.7175, 'percent': 71.7}, 'bbox': [45, 81, 79, 153]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.663, 'percent': 66.3}, 'bbox': [26, 62, 51, 127]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.6598, 'percent': 66.0}, 'bbox': [145, 59, 169, 156]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.6534, 'percent': 65.3}, 'bbox': [156, 61, 186, 178]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.6361, 'percent': 63.6}, 'bbox': [79, 54, 113, 184]}, {'class_id': 39, 'class_name': 'bottle', 'confidence': {'score': 0.5118, 'percent': 51.2}, 'bbox': [60, 16, 100, 101]}]\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We got list of classes and here it detect 8/10 bottles in our image.",
   "id": "2e433cde8990d45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **YOLO Inference Timing Flow**\n",
    "\n",
    "The YOLO output line:\n",
    "\n",
    "```\n",
    "\n",
    "test.jpg: 576x640 8 bottles, 214.9ms\n",
    "Speed: 8.5ms preprocess, 214.9ms inference, 3.8ms postprocess per image at shape (1, 3, 576, 640)\n",
    "\n",
    "```\n",
    "\n",
    "can be visualized as:\n",
    "\n",
    "```\n",
    "\n",
    "Input Image: test.jpg (576x640)\n",
    "â”‚\n",
    "â–¼\n",
    "Preprocess: 8.5ms\n",
    "\n",
    "* Load image\n",
    "* Resize & normalize\n",
    "* Convert to tensor\n",
    "* Send to GPU\n",
    "  â”‚\n",
    "  â–¼\n",
    "  Inference: 214.9ms\n",
    "* YOLO model predicts bounding boxes & class scores\n",
    "  â”‚\n",
    "  â–¼\n",
    "  Postprocess: 3.8ms\n",
    "* Non-Max Suppression (NMS)\n",
    "* Filter overlapping boxes\n",
    "* Scale boxes to original image\n",
    "  â”‚\n",
    "  â–¼\n",
    "  Output: 8 bottles detected\n",
    "  Total time: 214.9ms\n",
    "\n",
    "```\n",
    "\n",
    "**Explanation:**\n",
    "- **Preprocess:** Preparation before model runs.\n",
    "- **Inference:** Model does all predictions.\n",
    "- **Postprocess:** Refines and formats predictions.\n",
    "\n",
    "> **Note:** Most of the time is spent in **inference**, which grows with image size or model complexity.\n",
    "\n",
    "Hereâ€™s a clean Markdown snippet for your Jupyter Notebook explaining the input tensor shape:\n",
    "\n",
    "### **Input Tensor Shape**\n",
    "\n",
    "The YOLO model input tensor has the shape:\n",
    "\n",
    "```\n",
    "\n",
    "(1, 3, 576, 640)\n",
    "\n",
    "```\n",
    "\n",
    "**Breakdown:**\n",
    "\n",
    "| Dimension | Meaning |\n",
    "|-----------|---------|\n",
    "| 1         | Batch size (**one image**) |\n",
    "| 3         | Number of color channels (**RGB**) |\n",
    "| 576       | Image height in pixels |\n",
    "| 640       | Image width in pixels |\n",
    "\n",
    "> **Note:** YOLO requires input images to be resized and converted into a tensor of shape `(batch, channels, height, width)` before passing it through the model."
   ],
   "id": "cf76f08ae5563a92"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:16.174925Z",
     "start_time": "2025-09-27T11:34:16.165526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def annotate_image(image_path: str, detections: List[Dict]) -> np.ndarray:\n",
    "    img_bgr = cv2.imread(image_path)\n",
    "    if img_bgr is None:\n",
    "        raise FileNotFoundError(f\"Failed to read image: {image_path}\")\n",
    "    for det in detections:\n",
    "        x1, y1, x2, y2 = det[\"bbox\"]\n",
    "        label = f\"{det['class_name']} {det['confidence']['percent']}%\"\n",
    "        cv2.rectangle(img_bgr, (x1, y1), (x2, y2), (16, 185, 129), 2)\n",
    "        cv2.putText(img_bgr, label, (x1, y1 - 6),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.2,\n",
    "                    (0, 0, 0), 1, cv2.LINE_AA)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"Annotated Image\", img_rgb)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img_rgb"
   ],
   "id": "78c7d06249798b6e",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **`cv2.imread()`**\n",
    "\n",
    "- **What:**\n",
    "  OpenCV function to **read an image from disk**.\n",
    "\n",
    "- **Why:**\n",
    "  Loads the image into a **NumPy array** in **BGR format**.\n",
    "  > Note: OpenCV uses **Blue-Green-Red (BGR) channel order** by default, not RGB.\n",
    "\n",
    "\n",
    "### **`cv2.rectangle()`**\n",
    "\n",
    "Draws a rectangle on an image typically used for **bounding boxes** around detected objects.\n",
    "\n",
    "```python\n",
    "cv2.rectangle(img_bgr, (x1, y1), (x2, y2), (16, 185, 129), 2)\n",
    "````\n",
    "\n",
    "**Breakdown of parameters:**\n",
    "\n",
    "| Parameter        | What it is                           | Why                                                            |\n",
    "| ---------------- | ------------------------------------ | -------------------------------------------------------------- |\n",
    "| `img_bgr`        | The image array (in BGR format)      | Rectangle will be drawn directly on this image                 |\n",
    "| `(x1, y1)`       | Top-left corner of the rectangle     | Defines where the rectangle starts                             |\n",
    "| `(x2, y2)`       | Bottom-right corner of the rectangle | Defines where the rectangle ends                               |\n",
    "| `(16, 185, 129)` | BGR color tuple for the rectangle    | Chooses a visible color (here, a shade of green)               |\n",
    "| `2`              | Line thickness in pixels             | Determines how thick the rectangle border appears on the image |\n",
    "\n",
    "> **Note:** OpenCV uses **BGR** order, not RGB, for colors.\n",
    "\n",
    "### **`cv2.putText()`**\n",
    "\n",
    "Draws text on an image typically used to **display the class name and confidence** above a bounding box.\n",
    "\n",
    "```python\n",
    "cv2.putText(img_bgr, label, (x1, y1 - 6),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.2,\n",
    "            (0, 0, 0), 1, cv2.LINE_AA)\n",
    "````\n",
    "\n",
    "**Breakdown of parameters:**\n",
    "\n",
    "| Parameter                  | What it is                                            | Why                                                            |\n",
    "|----------------------------| ----------------------------------------------------- | -------------------------------------------------------------- |\n",
    "| `img_bgr`                  | The image array where text will be drawn (BGR format) | Text appears directly on this image alongside the bounding box |\n",
    "| `label`                    | Text string (e.g., `\"bottle 92.1%\"`)                  | Displays the **object name and confidence**                    |\n",
    "| `(x1, y1 - 6)`             | Bottom-left corner coordinates of the text            | Slightly above the bounding box to avoid overlap               |\n",
    "| `cv2.FONT_HERSHEY_SIMPLEX` | Predefined OpenCV font type                           | Determines the **style of the text**                           |\n",
    "| `0.2`                      | Font scale                                            | Controls **text size** (0.5 = moderately small)                |\n",
    "| `(0, 0, 0)`                | Text color in BGR (white)                             | Ensures high visibility against most backgrounds               |\n",
    "| `1`                        | Thickness of the text stroke                          | Determines how bold the text appears                           |\n",
    "| `cv2.LINE_AA`              | Anti-aliased line type                                | Smooths edges for better readability                           |\n",
    "\n",
    "> **Note:** Using anti-aliasing (`cv2.LINE_AA`) makes the text **look smoother and more professional**.\n",
    "\n",
    "### **Converting BGR to RGB**\n",
    "\n",
    "```python\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "````\n",
    "\n",
    "**Breakdown of components:**\n",
    "\n",
    "| Component           | What it is                                      | Why                                                               |\n",
    "| ------------------- | ----------------------------------------------- | ----------------------------------------------------------------- |\n",
    "| `img_rgb`           | New variable storing the converted image        | Needed in **RGB format** for consistent display (matplotlib, web) |\n",
    "| `cv2.cvtColor()`    | OpenCV function to convert image color spaces   | Converts BGR â†’ RGB                                                |\n",
    "| `img_bgr`           | Input image in **BGR format**                   | Source image with drawn bounding boxes and text                   |\n",
    "| `cv2.COLOR_BGR2RGB` | OpenCV constant specifying BGR â†’ RGB conversion | Ensures red, green, and blue channels are correctly reordered     |\n",
    "\n",
    "> **Note:** OpenCV uses **BGR by default**, while most display libraries (matplotlib, PIL, browsers) expect **RGB**. This conversion prevents color distortion."
   ],
   "id": "55bcefd316d33ac4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Now annotation is also working",
   "id": "3995458771252922"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.254849Z",
     "start_time": "2025-09-27T11:34:16.190864Z"
    }
   },
   "cell_type": "code",
   "source": "annotate_image(\"test.jpg\",detect)",
   "id": "458a85d88e3af4b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]],\n",
       "\n",
       "       [[255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255],\n",
       "        [255, 255, 255]]], shape=(211, 239, 3), dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **LETS CREATE SERVICE LAYER**",
   "id": "d72520880a9469eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.307479Z",
     "start_time": "2025-09-27T11:34:19.300805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "import cv2\n",
    "import json\n",
    "from pathlib import Path\n",
    "from Backend.app.models.yolo_detector import YOLODetector"
   ],
   "id": "22c7dda29984f8da",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Imports Overview**\n",
    "\n",
    "- `base64` â†’ Convert images to **base64 strings** for JSON-safe API responses.\n",
    "- `cv2` â†’ OpenCV for **image processing** (drawing, encoding, color conversion).\n",
    "- `json` â†’ Load JSON files like `reuse_mapping.json` into Python dicts.\n",
    "- `Path` from `pathlib` â†’ Modern, **cross-platform file path management** better than os.path.\n",
    "- `YOLODetector` â†’ Our custom class for **running YOLO detections**."
   ],
   "id": "48818b9d0aa50a20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Python `pathlib` Module (`Path`)\n",
    "\n",
    "The `pathlib` module provides **classes to handle filesystem paths** in an object-oriented way. It's modern, readable, and safer than using string paths with `os.path`.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Importing Path\n",
    "```python\n",
    "from pathlib import Path\n",
    "````\n",
    "\n",
    "* `Path` is the main class representing a **file or directory path**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Creating Paths\n",
    "\n",
    "```python\n",
    "p = Path(\"C:/Users/Shivansh/Documents\")  # Absolute path\n",
    "q = Path(\"my_folder/my_file.txt\")        # Relative path\n",
    "```\n",
    "\n",
    "* Handles forward slashes `/` on any OS.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Checking Path Properties\n",
    "\n",
    "```python\n",
    "p.exists()   # True if path exists\n",
    "p.is_file()  # True if path is a file\n",
    "p.is_dir()   # True if path is a directory\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Path Operations\n",
    "\n",
    "### Joining Paths\n",
    "\n",
    "```python\n",
    "p = Path(\"C:/Users/Shivansh\")\n",
    "q = p / \"Documents\" / \"file.txt\"\n",
    "print(q)  # C:/Users/Shivansh/Documents/file.txt\n",
    "```\n",
    "\n",
    "* `/` operator joins paths (cleaner than `os.path.join`).\n",
    "\n",
    "### Getting parts of a path\n",
    "\n",
    "```python\n",
    "print(q.name)     # file.txt\n",
    "print(q.stem)     # file\n",
    "print(q.suffix)   # .txt\n",
    "print(q.parent)   # C:/Users/Shivansh/Documents\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Creating Directories or Files\n",
    "\n",
    "```python\n",
    "p = Path(\"new_folder\")\n",
    "p.mkdir(exist_ok=True)  # Create folder if not exists\n",
    "\n",
    "file_path = p / \"my_file.txt\"\n",
    "file_path.touch()        # Create empty file\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Iterating Over Files\n",
    "\n",
    "```python\n",
    "p = Path(\"C:/Users/Shivansh/Documents\")\n",
    "for file in p.iterdir():\n",
    "    print(file)\n",
    "```\n",
    "\n",
    "### Filtering by extension\n",
    "\n",
    "```python\n",
    "for file in p.glob(\"*.txt\"):\n",
    "    print(file)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Reading and Writing Files\n",
    "\n",
    "```python\n",
    "file = Path(\"example.txt\")\n",
    "\n",
    "file.write_text(\"Hello Python!\")   # Write to file\n",
    "content = file.read_text()         # Read from file\n",
    "print(content)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Advantages of `pathlib` over `os.path`\n",
    "\n",
    "1. Object-oriented â€“ paths are objects with methods.\n",
    "2. Cross-platform safe.\n",
    "3. Cleaner syntax (`/` operator for joining).\n",
    "4. Powerful : iteration, globbing, reading/writing.\n"
   ],
   "id": "165f5377178613b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### **_Path.cwd() gets the current path of our file , then .parent just means go 1 time up to parent_**",
   "id": "3411cd1a1a12f88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.347852Z",
     "start_time": "2025-09-27T11:34:19.339337Z"
    }
   },
   "cell_type": "code",
   "source": "Path.cwd().parent / \"app\" / \"data\" / \"reuse_mapping.json\"",
   "id": "1efff5742cd115e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/PycharmProjects/Eco_Vision/Backend/app/data/reuse_mapping.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.417313Z",
     "start_time": "2025-09-27T11:34:19.408705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path = Path.cwd().parent / \"app\" / \"data\" / \"reuse_mapping.json\"\n",
    "with open(data_path, \"r\") as f:\n",
    "    reuse_mapping = json.load(f)"
   ],
   "id": "b568164a6728e220",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Now we add reuse tips using below fn and return detection list of dict + annonated images in base64 format",
   "id": "3be376b53c574a0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T12:28:12.279738Z",
     "start_time": "2025-09-27T12:28:12.271758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_detection(image_path: str, conf: float = 0.5) -> dict:\n",
    "\n",
    "    detections = detect_objects(image_path, conf=conf)  # get raw detections from YOLO.\n",
    "\n",
    "    for d in detections:\n",
    "        cls = d[\"class_name\"]\n",
    "        d[\"reuse_tip\"] = reuse_mapping.get(cls, \"No tip available\")\n",
    "\n",
    "    # Annotate\n",
    "    annotated_img = annotate_image(image_path, detections)\n",
    "\n",
    "    # Step 4: Convert annotated image to base64 (for JSON return)\n",
    "    _, buffer = cv2.imencode(\".jpg\", cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "    img_base64 = base64.b64encode(buffer).decode(\"utf-8\")\n",
    "\n",
    "    return {\n",
    "        \"detections\": detections,\n",
    "        \"annotated_image\": img_base64,\n",
    "        \"total_items\": len(detections)\n",
    "    }"
   ],
   "id": "435d13f9686cd0a4",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### _Here u can see that imencode() gives us tuple._",
   "id": "536c4c1988c2c8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.483936Z",
     "start_time": "2025-09-27T11:34:19.472403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1. Create a dummy image (RGB)\n",
    "img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "img[:] = [255, 0, 0]  # fill with red\n",
    "\n",
    "# 2. Encode the image to JPG in memory\n",
    "buffer = cv2.imencode(\".jpg\", cv2.cvtColor(img, cv2.COLOR_RGB2BGR)) #its a tuple (ecoding is succeeded or not , nd.array )\n",
    "print(buffer)"
   ],
   "id": "5f363f693c582695",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(True, array([255, 216, 255, 224,   0,  16,  74,  70,  73,  70,   0,   1,   1,   0,   0,   1,   0,   1,   0,   0, 255, 219,   0,  67,   0,   2,   1,   1,   1,   1,   1,   2,   1,   1,   1,   2,   2,   2,   2,   2,   4,   3,   2,   2,   2,   2,   5,   4,   4,   3,   4,   6,   5,   6,   6,   6,   5,   6,   6,   6,   7,   9,\n",
      "         8,   6,   7,   9,   7,   6,   6,   8,  11,   8,   9,  10,  10,  10,  10,  10,   6,   8,  11,  12,  11,  10,  12,   9,  10,  10,  10, 255, 219,   0,  67,   1,   2,   2,   2,   2,   2,   2,   5,   3,   3,   5,  10,   7,   6,   7,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,\n",
      "        10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10,  10, 255, 192,   0,  17,   8,   0, 100,   0, 100,   3,   1,  34,   0,   2,  17,   1,   3,  17,   1, 255, 196,   0,  31,   0,   0,   1,   5,   1,\n",
      "         1,   1,   1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11, 255, 196,   0, 181,  16,   0,   2,   1,   3,   3,   2,   4,   3,   5,   5,   4,   4,   0,   0,   1, 125,   1,   2,   3,   0,   4,  17,   5,  18,  33,  49,  65,   6,  19,  81,  97,   7,  34,\n",
      "       113,  20,  50, 129, 145, 161,   8,  35,  66, 177, 193,  21,  82, 209, 240,  36,  51,  98, 114, 130,   9,  10,  22,  23,  24,  25,  26,  37,  38,  39,  40,  41,  42,  52,  53,  54,  55,  56,  57,  58,  67,  68,  69,  70,  71,  72,  73,  74,  83,  84,  85,  86,  87,  88,  89,  90,  99, 100, 101, 102, 103, 104,\n",
      "       105, 106, 115, 116, 117, 118, 119, 120, 121, 122, 131, 132, 133, 134, 135, 136, 137, 138, 146, 147, 148, 149, 150, 151, 152, 153, 154, 162, 163, 164, 165, 166, 167, 168, 169, 170, 178, 179, 180, 181, 182, 183, 184, 185, 186, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 211, 212, 213, 214, 215, 216, 217,\n",
      "       218, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 255, 196,   0,  31,   1,   0,   3,   1,   1,   1,   1,   1,   1,   1,   1,   1,   0,   0,   0,   0,   0,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11, 255, 196,   0, 181,  17,   0,   2,   1,\n",
      "         2,   4,   4,   3,   4,   7,   5,   4,   4,   0,   1,   2, 119,   0,   1,   2,   3,  17,   4,   5,  33,  49,   6,  18,  65,  81,   7,  97, 113,  19,  34,  50, 129,   8,  20,  66, 145, 161, 177, 193,   9,  35,  51,  82, 240,  21,  98, 114, 209,  10,  22,  36,  52, 225,  37, 241,  23,  24,  25,  26,  38,  39,\n",
      "        40,  41,  42,  53,  54,  55,  56,  57,  58,  67,  68,  69,  70,  71,  72,  73,  74,  83,  84,  85,  86,  87,  88,  89,  90,  99, 100, 101, 102, 103, 104, 105, 106, 115, 116, 117, 118, 119, 120, 121, 122, 130, 131, 132, 133, 134, 135, 136, 137, 138, 146, 147, 148, 149, 150, 151, 152, 153, 154, 162, 163, 164,\n",
      "       165, 166, 167, 168, 169, 170, 178, 179, 180, 181, 182, 183, 184, 185, 186, 194, 195, 196, 197, 198, 199, 200, 201, 202, 210, 211, 212, 213, 214, 215, 216, 217, 218, 226, 227, 228, 229, 230, 231, 232, 233, 234, 242, 243, 244, 245, 246, 247, 248, 249, 250, 255, 218,   0,  12,   3,   1,   0,   2,  17,   3,  17,\n",
      "         0,  63,   0, 248, 190, 138,  40, 175, 229,  51, 253, 252,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40,\n",
      "       162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,\n",
      "        10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40,\n",
      "       162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  10,  40, 162, 128,  63, 255, 217], dtype=uint8))\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Converting Annotated Image to Base64 for JSON**\n",
    "\n",
    "**Step 1:** Convert RGB â†’ BGR\n",
    "```python\n",
    "cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR)\n",
    "````\n",
    "\n",
    "* OpenCV expects **BGR** internally.\n",
    "* Ensures colors display correctly when encoding.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2:** Encode as JPEG\n",
    "\n",
    "```python\n",
    "_, buffer = cv2.imencode(\".jpg\", img_bgr)\n",
    "```\n",
    "\n",
    "* Converts the image array into **JPEG bytes**.\n",
    "* `_` â†’ status (ignored), `buffer` â†’ byte array of the image.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 3:** Convert bytes â†’ base64 string\n",
    "\n",
    "```python\n",
    "img_base64 = base64.b64encode(buffer).decode(\"utf-8\")\n",
    "```\n",
    "\n",
    "* `base64.b64encode(buffer)` â†’ bytes â†’ safe for JSON.\n",
    "* `.decode(\"utf-8\")` â†’ converts bytes to a **normal Python string**.\n",
    "\n",
    "---\n",
    "\n",
    "**Why:**\n",
    "\n",
    "* The frontend can **display the image directly** without saving a file to disk.\n",
    "* Makes sending images in **API responses easy and safe**."
   ],
   "id": "f1ae798d8fb1e8ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T11:34:19.548882Z",
     "start_time": "2025-09-27T11:34:19.543286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Convert to base64 string\n",
    "img_base64 = base64.b64encode(buffer[1]).decode(\"utf-8\")\n",
    "print(img_base64)"
   ],
   "id": "ff59fdc24246ca5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYFBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/2wBDAQICAgICAgUDAwUKBwYHCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgr/wAARCABkAGQDASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD4vooor+Uz/fwKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooA//9k=\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Output**\n",
    "\n",
    "We get **two things**:\n",
    "1. **List of dicts** â†’ enriched with reuse tips.\n",
    "2. **Base64 annotated image** â†’ ready for JSON response."
   ],
   "id": "48865392a8c40c5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T12:28:17.856744Z",
     "start_time": "2025-09-27T12:28:15.793182Z"
    }
   },
   "cell_type": "code",
   "source": "run_detection(\"test.jpg\", conf=0.5)",
   "id": "53b09193e0ca910b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\PycharmProjects\\Eco_Vision\\Backend\\ML notebook\\test.jpg: 576x640 8 bottles, 225.8ms\n",
      "Speed: 5.8ms preprocess, 225.8ms inference, 9.6ms postprocess per image at shape (1, 3, 576, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'detections': [{'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.9479, 'percent': 94.8},\n",
       "   'bbox': [190, 67, 222, 181],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.7831, 'percent': 78.3},\n",
       "   'bbox': [26, 62, 51, 155],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.7175, 'percent': 71.7},\n",
       "   'bbox': [45, 81, 79, 153],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.663, 'percent': 66.3},\n",
       "   'bbox': [26, 62, 51, 127],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.6598, 'percent': 66.0},\n",
       "   'bbox': [145, 59, 169, 156],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.6534, 'percent': 65.3},\n",
       "   'bbox': [156, 61, 186, 178],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.6361, 'percent': 63.6},\n",
       "   'bbox': [79, 54, 113, 184],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'},\n",
       "  {'class_id': 39,\n",
       "   'class_name': 'bottle',\n",
       "   'confidence': {'score': 0.5118, 'percent': 51.2},\n",
       "   'bbox': [60, 16, 100, 101],\n",
       "   'reuse_tip': 'Reuse bottles for water storage instead of single-use plastic.'}],\n",
       " 'annotated_image': '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',\n",
       " 'total_items': 8}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### **Base64 Conversion in `detection_service.py`**\n",
    "\n",
    "```python\n",
    "_, buffer = cv2.imencode(\".jpg\", cv2.cvtColor(annotated_img, cv2.COLOR_RGB2BGR))\n",
    "img_base64 = base64.b64encode(buffer).decode(\"utf-8\")\n",
    "````\n",
    "\n",
    "* `annotated_img` â†’ RGB array from `yolo_detector`\n",
    "* `cv2.cvtColor(..., cv2.COLOR_RGB2BGR)` â†’ convert to BGR for `cv2.imencode()`\n",
    "* `cv2.imencode(\".jpg\", ...)` â†’ encode BGR image as JPEG bytes\n",
    "* `base64.b64encode(buffer)` â†’ bytes â†’ base64 string for JSON\n",
    "\n",
    "**Key point:**\n",
    "\n",
    "* Base64 JPEG string **doesnâ€™t care about BGR/RGB**; frontend will display it correctly.\n",
    "* BGR â†’ RGB conversion only matters when working with **raw NumPy arrays**, not encoded JPEGs."
   ],
   "id": "162be1d6fd93e796"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **LETS WORK ON API LAYER**",
   "id": "812f634ccdb076a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:00:45.898208Z",
     "start_time": "2025-09-27T13:00:31.646806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install fastapi\n",
    "!{sys.executable} -m pip install \"uvicorn[standard]\"\n",
    "!{sys.executable} -m pip install python-multipart"
   ],
   "id": "b1bfb8a5b3d734c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastapi\n",
      "  Using cached fastapi-0.117.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting starlette<0.49.0,>=0.40.0 (from fastapi)\n",
      "  Using cached starlette-0.48.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 (from fastapi)\n",
      "  Using cached pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from fastapi) (4.15.0)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Using cached fastapi-0.117.1-py3-none-any.whl (95 kB)\n",
      "Using cached pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached starlette-0.48.0-py3-none-any.whl (73 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, pydantic-core, annotated-types, starlette, pydantic, fastapi\n",
      "Successfully installed annotated-types-0.7.0 fastapi-0.117.1 pydantic-2.11.9 pydantic-core-2.33.2 starlette-0.48.0 typing-inspection-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: D:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uvicorn[standard] in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (0.37.0)\n",
      "Requirement already satisfied: click>=7.0 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from uvicorn[standard]) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from uvicorn[standard]) (0.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from uvicorn[standard]) (0.4.6)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
      "  Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from uvicorn[standard]) (1.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from uvicorn[standard]) (6.0.2)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "  Downloading watchfiles-1.1.0-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: anyio>=3.0.0 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from watchfiles>=0.13->uvicorn[standard]) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in d:\\pycharmprojects\\eco_vision\\backend\\venv\\lib\\site-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (1.3.1)\n",
      "Downloading httptools-0.6.4-cp313-cp313-win_amd64.whl (87 kB)\n",
      "Downloading watchfiles-1.1.0-cp313-cp313-win_amd64.whl (292 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Installing collected packages: websockets, httptools, watchfiles\n",
      "Successfully installed httptools-0.6.4 watchfiles-1.1.0 websockets-15.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: D:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-multipart\n",
      "  Using cached python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: python-multipart\n",
      "Successfully installed python-multipart-0.0.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: D:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Imports (API / Detection)**\n",
    "\n",
    "1. `from pathlib import Path` â†’ Modern, cross-platform **Path object** for file paths. Safer than strings + `os.path.join`.\n",
    "2. `import base64` â†’ Encode images to **base64 strings** for JSON; frontend can decode to display annotated images.\n",
    "3. `from fastapi import ...` â†’ FastAPI app, handle uploads (`File`, `UploadFile`), form fields (`Form`), and raise HTTP errors (`HTTPException`).\n",
    "4. `from fastapi.middleware.cors import CORSMiddleware` â†’ Handle **CORS** for frontend requests from different origins.\n",
    "5. `from fastapi.responses import JSONResponse` â†’ Return structured JSON responses.\n",
    "6. `import cv2` â†’ OpenCV for image processing: annotate images, convert RGBâ†”BGR, encode JPEG.\n",
    "7. `import os` â†’ Environment variables and OS operations.\n",
    "8. `from Backend.app.services.detection_service import DetectionService` â†’ Custom service wrapping YOLO, reuse tips, and image annotation.\n",
    "9. `import tempfile` â†’ Temporary files/directories; safer than saving uploads in project folder."
   ],
   "id": "20ba05ed627140a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 44,
   "source": [
    "from pathlib import Path\n",
    "import base64\n",
    "from fastapi import FastAPI, File, UploadFile, Form, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import JSONResponse\n",
    "import cv2\n",
    "import os\n",
    "from Backend.app.services.detection_service import DetectionService\n",
    "import tempfile"
   ],
   "id": "d73eee4b0c14fd48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:05:44.161679Z",
     "start_time": "2025-09-27T13:05:44.153749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize FastAPI app\n",
    "app = FastAPI(title=\"Reusable Item Detector API\")"
   ],
   "id": "7496389551ec789a",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Explanation:**\n",
    "\n",
    "1. **Allowed Origins:**\n",
    "\n",
    "```python\n",
    "allowed_origins = [origin.strip() for origin in os.getenv(\"ALLOWED_ORIGINS\", \"http://localhost:3000\").split(\",\")]\n",
    "```\n",
    "\n",
    "* Reads `ALLOWED_ORIGINS` environment variable (e.g., `\"http://localhost:3000,http://example.com\"`).\n",
    "* Splits into a **list of domains** and strips extra spaces.\n",
    "* Only these domains can call your API.\n",
    "\n",
    "2. **Add Middleware:**\n",
    "\n",
    "```python\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=allowed_origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")\n",
    "```\n",
    "\n",
    "* Adds **CORS support** to FastAPI.\n",
    "* `allow_credentials=True` â†’ allows cookies/auth headers.\n",
    "* `allow_methods=[\"*\"]` â†’ all HTTP methods allowed.\n",
    "* `allow_headers=[\"*\"]` â†’ all request headers allowed."
   ],
   "id": "2d4854afd46680b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 46,
   "source": [
    "allowed_origins = (\n",
    "    [origin.strip() for origin in (os.getenv(\"ALLOWED_ORIGINS\", \"http://localhost:3000\").split(\",\"))]\n",
    ")"
   ],
   "id": "13c04cc16e60fe6a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 47,
   "source": [
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=allowed_origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")"
   ],
   "id": "7892d42a6463c684"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:23:35.955504Z",
     "start_time": "2025-09-27T13:23:35.695271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize service layers\n",
    "detection_service = DetectionService()"
   ],
   "id": "28c90f1857e0567a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[YOLODetector] Loaded model: yolo12n.pt on cpu\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:29:17.486925Z",
     "start_time": "2025-09-27T13:29:17.478840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Health check endpoint\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    \"\"\"\n",
    "    Simple health check endpoint.\n",
    "    \"\"\"\n",
    "    return {\"status\": \"healthy\"}"
   ],
   "id": "3dd79b87d5d3d527",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "async def health() â†’ asynchronous function for handling multiple requests concurrently.",
   "id": "a5101cb420a202f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T13:54:10.814515Z",
     "start_time": "2025-09-27T13:54:10.747639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Detection endpoint\n",
    "\n",
    "@app.post(\"/detect\")\n",
    "async def detect(\n",
    "    file: UploadFile = File(...),\n",
    "    confidence: float = Form(0.5)\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload an image, run detection and return JSON response with detections and annotated image.\n",
    "    \"\"\"\n",
    "\n",
    "    #  Validate uploaded file\n",
    "    if not file.content_type.startswith(\"image/\"):\n",
    "        raise HTTPException(status_code=400, detail=\"Uploaded file must be an image\")\n",
    "\n",
    "    #  Save uploaded file temporarily using tempfile\n",
    "    temp_dir = Path(tempfile.gettempdir())\n",
    "    temp_path = temp_dir / f\"tmp_{file.filename}\"\n",
    "    try:\n",
    "        with temp_path.open(\"wb\") as f:\n",
    "            f.write(await file.read())\n",
    "\n",
    "        #  Run detection\n",
    "        result = detection_service.run_detection(str(temp_path), confidence)\n",
    "\n",
    "        #  Convert annotated image to base64 (if available)\n",
    "        annotated_b64 = None\n",
    "        if result.get(\"annotated_image\") is not None:\n",
    "            # OpenCV expects BGR for encoding\n",
    "            bgr_img = cv2.cvtColor(result[\"annotated_image\"], cv2.COLOR_RGB2BGR)\n",
    "            _, buf = cv2.imencode(\".jpg\", bgr_img)\n",
    "            annotated_b64 = base64.b64encode(buf).decode(\"utf-8\")\n",
    "\n",
    "        #  Build JSON response\n",
    "        resp = {\n",
    "            \"success\": True,\n",
    "            \"detections\": result.get(\"detections\", []),\n",
    "            \"annotated_image\": annotated_b64,\n",
    "            \"total_items\": result.get(\"total_items\", 0) #defaults to 0 if key is missing.\n",
    "        }\n",
    "\n",
    "        return JSONResponse(content=resp)\n",
    "\n",
    "    finally:\n",
    "        # Cleanup temporary file\n",
    "        if temp_path.exists():\n",
    "            temp_path.unlink()"
   ],
   "id": "c54e7fd2a56e6296",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Parameters:**\n",
    "\n",
    "   * `file: UploadFile = File(...)` â†’ required uploaded image file with access to name, type, content.\n",
    "   * `confidence: float = Form(0.5)` â†’ optional threshold for detection confidence.\n",
    "\n",
    "**Temporary saving:**\n",
    "\n",
    "* `temp_dir = Path(tempfile.gettempdir())` â†’ OS temp folder.\n",
    "* `temp_path = temp_dir / f\"tmp_{file.filename}\"` â†’ safe temp file path.\n",
    "* `with temp_path.open(\"wb\") as f: f.write(await file.read())` â†’ writes uploaded bytes asynchronously.\n",
    "\n",
    "**Return JSON Response**\n",
    "\n",
    "* Converts Python dict `resp` into **JSON**.\n",
    "* Sends it to the client with `Content-Type: application/json`.\n",
    "* FastAPI automatic sets **HTTP 200 OK** for successful responses.\n",
    "\n",
    "\n",
    "**Temporary File Cleanup**\n",
    "\n",
    "**Delete file:** `temp_path.unlink()` removes the temporary file safely using `Path` object."
   ],
   "id": "4bbec1f760ce71b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2578afecaff8cc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (backend-env)",
   "language": "python",
   "name": "backend-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
