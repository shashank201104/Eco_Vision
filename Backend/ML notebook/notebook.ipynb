{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **Importing all the modules**\n",
    "\n",
    "\n",
    "YOLO (from ultralytics): load and run the YOLOv8 model.\n",
    "\n",
    "cv2: read/write images, draw boxes, color conversions.\n",
    "\n",
    "numpy as np: image arrays and numeric operations.\n",
    "\n",
    "typing.List/Dict: type annotations for clarity.\n",
    "\n",
    "torch: detect GPU availability (torch.cuda.is_available()).\n",
    "\n",
    "os: read env vars and check file paths."
   ],
   "id": "3f8fe2d6e80e0435"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T04:25:59.555582Z",
     "start_time": "2025-09-26T04:25:48.407040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import torch\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\HP\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T06:02:04.242404Z",
     "start_time": "2025-09-26T06:02:04.231841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"D:\\PycharmProjects\\Eco_Vision\\Backend\\.env\")"
   ],
   "id": "2fc2c6d3bcc58c95",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7424\\2373333911.py:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  load_dotenv(dotenv_path=\"D:\\PycharmProjects\\Eco_Vision\\Backend\\.env\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "_**device:**_ force CPU/GPU manually if you want otherwise we auto-detect later.\n",
    "Pick **_model_path_** use environment variable MODEL_PATH, else default to \"yolov8n.pt\".\n",
    "_**YOLO(model_path):**_calls the YOLO class (from Ultralytics) with model_path.\n",
    "         -> This loads the pretrained model into memory.\n",
    "         -> **NOTE:** we load the model once in the constructor when I write the script, so we donâ€™t have to reload it every time we detect something.\n"
   ],
   "id": "ccd65e4d440f98c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T06:03:04.886583Z",
     "start_time": "2025-09-26T06:03:03.409687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.getenv(\"MODEL_PATH\",None) #if we didn't set model , default this come \"yolov8n.pt\"\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = YOLO(model_path)"
   ],
   "id": "8600596ecb2f6898",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'yolov12n.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m model_path = os.getenv(\u001B[33m\"\u001B[39m\u001B[33mMODEL_PATH\u001B[39m\u001B[33m\"\u001B[39m,\u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;66;03m#if we didn't set model , default this come \"yolov8n.pt\"\u001B[39;00m\n\u001B[32m      2\u001B[39m device = (\u001B[33m\"\u001B[39m\u001B[33mcuda\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m torch.cuda.is_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mcpu\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m model = \u001B[43mYOLO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\models\\yolo\\model.py:83\u001B[39m, in \u001B[36mYOLO.__init__\u001B[39m\u001B[34m(self, model, task, verbose)\u001B[39m\n\u001B[32m     80\u001B[39m     \u001B[38;5;28mself\u001B[39m.\u001B[34m__dict__\u001B[39m = new_instance.\u001B[34m__dict__\u001B[39m\n\u001B[32m     81\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     82\u001B[39m     \u001B[38;5;66;03m# Continue with default YOLO initialization\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m83\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m=\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     84\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.model, \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mRTDETR\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model.model[-\u001B[32m1\u001B[39m]._get_name():  \u001B[38;5;66;03m# if RTDETR head\u001B[39;00m\n\u001B[32m     85\u001B[39m         \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01multralytics\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m RTDETR\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:153\u001B[39m, in \u001B[36mModel.__init__\u001B[39m\u001B[34m(self, model, task, verbose)\u001B[39m\n\u001B[32m    151\u001B[39m     \u001B[38;5;28mself\u001B[39m._new(model, task=task, verbose=verbose)\n\u001B[32m    152\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m153\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    155\u001B[39m \u001B[38;5;66;03m# Delete super().training for accessing self.model.training\u001B[39;00m\n\u001B[32m    156\u001B[39m \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m.training\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\engine\\model.py:297\u001B[39m, in \u001B[36mModel._load\u001B[39m\u001B[34m(self, weights, task)\u001B[39m\n\u001B[32m    294\u001B[39m weights = checks.check_model_file_from_stem(weights)  \u001B[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001B[39;00m\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(weights).rpartition(\u001B[33m\"\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)[-\u001B[32m1\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m297\u001B[39m     \u001B[38;5;28mself\u001B[39m.model, \u001B[38;5;28mself\u001B[39m.ckpt = \u001B[43mload_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweights\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    298\u001B[39m     \u001B[38;5;28mself\u001B[39m.task = \u001B[38;5;28mself\u001B[39m.model.task\n\u001B[32m    299\u001B[39m     \u001B[38;5;28mself\u001B[39m.overrides = \u001B[38;5;28mself\u001B[39m.model.args = \u001B[38;5;28mself\u001B[39m._reset_ckpt_args(\u001B[38;5;28mself\u001B[39m.model.args)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1501\u001B[39m, in \u001B[36mload_checkpoint\u001B[39m\u001B[34m(weight, device, inplace, fuse)\u001B[39m\n\u001B[32m   1487\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_checkpoint\u001B[39m(weight, device=\u001B[38;5;28;01mNone\u001B[39;00m, inplace=\u001B[38;5;28;01mTrue\u001B[39;00m, fuse=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m   1488\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   1489\u001B[39m \u001B[33;03m    Load a single model weights.\u001B[39;00m\n\u001B[32m   1490\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   1499\u001B[39m \u001B[33;03m        ckpt (dict): Model checkpoint dictionary.\u001B[39;00m\n\u001B[32m   1500\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1501\u001B[39m     ckpt, weight = \u001B[43mtorch_safe_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# load ckpt\u001B[39;00m\n\u001B[32m   1502\u001B[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001B[33m\"\u001B[39m\u001B[33mtrain_args\u001B[39m\u001B[33m\"\u001B[39m, {}))}  \u001B[38;5;66;03m# combine model and default args, preferring model args\u001B[39;00m\n\u001B[32m   1503\u001B[39m     model = (ckpt.get(\u001B[33m\"\u001B[39m\u001B[33mema\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m ckpt[\u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m]).float()  \u001B[38;5;66;03m# FP32 model\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\nn\\tasks.py:1448\u001B[39m, in \u001B[36mtorch_safe_load\u001B[39m\u001B[34m(weight, safe_only)\u001B[39m\n\u001B[32m   1446\u001B[39m                 ckpt = torch_load(f, pickle_module=safe_pickle)\n\u001B[32m   1447\u001B[39m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1448\u001B[39m             ckpt = \u001B[43mtorch_load\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_location\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mcpu\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1450\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# e.name is missing module name\u001B[39;00m\n\u001B[32m   1451\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m e.name == \u001B[33m\"\u001B[39m\u001B[33mmodels\u001B[39m\u001B[33m\"\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\ultralytics\\utils\\patches.py:120\u001B[39m, in \u001B[36mtorch_load\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    117\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m TORCH_1_13 \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mweights_only\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[32m    118\u001B[39m     kwargs[\u001B[33m\"\u001B[39m\u001B[33mweights_only\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m120\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\torch\\serialization.py:1484\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[39m\n\u001B[32m   1481\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args.keys():\n\u001B[32m   1482\u001B[39m     pickle_load_args[\u001B[33m\"\u001B[39m\u001B[33mencoding\u001B[39m\u001B[33m\"\u001B[39m] = \u001B[33m\"\u001B[39m\u001B[33mutf-8\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m1484\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_file_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[32m   1485\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[32m   1486\u001B[39m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[32m   1487\u001B[39m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[32m   1488\u001B[39m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[32m   1489\u001B[39m         orig_position = opened_file.tell()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\torch\\serialization.py:759\u001B[39m, in \u001B[36m_open_file_like\u001B[39m\u001B[34m(name_or_buffer, mode)\u001B[39m\n\u001B[32m    757\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_open_file_like\u001B[39m(name_or_buffer: FileLike, mode: \u001B[38;5;28mstr\u001B[39m) -> _opener[IO[\u001B[38;5;28mbytes\u001B[39m]]:\n\u001B[32m    758\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[32m--> \u001B[39m\u001B[32m759\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_open_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    760\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    761\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mw\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\PycharmProjects\\Eco_Vision\\backend\\venv\\Lib\\site-packages\\torch\\serialization.py:740\u001B[39m, in \u001B[36m_open_file.__init__\u001B[39m\u001B[34m(self, name, mode)\u001B[39m\n\u001B[32m    739\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: Union[\u001B[38;5;28mstr\u001B[39m, os.PathLike[\u001B[38;5;28mstr\u001B[39m]], mode: \u001B[38;5;28mstr\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m740\u001B[39m     \u001B[38;5;28msuper\u001B[39m().\u001B[34m__init__\u001B[39m(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: 'yolov12n.pt'"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "de5a5cdd88d10b7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### as here  below we can see our model is lock & loaded on cpu not gpu as i dont have didicated graphic card ðŸ’€.",
   "id": "385e0a33dc2be99a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-26T05:40:10.946048Z",
     "start_time": "2025-09-26T05:40:10.939502Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"[YOLODetector] Loaded model: {model_path} on {device}\")",
   "id": "80079dd8ff0c20f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[YOLODetector] Loaded model: yolov8n.pt on cpu\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "we are using very small model here and it it fatest",
   "id": "6dc83d3ba126c231"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (backend-env)",
   "language": "python",
   "name": "backend-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
