# ğŸŒ± **Eco Vision â€“ FastAPI Backend**

*A custom-trained YOLO object-detection API that promotes recycling, reuse, and sustainability.*

The Eco Vision backend:

* Runs detection using **your custom YOLO model**
* Attaches **reuse / recycling tips** for each detected item
* Returns **annotated images** (Base64)
* Powers the Eco Vision frontend
* Is deployed on **Render**
* Includes the **full ML training workflow** and all YOLO training outputs

This is your complete AI inference system.

---

# ğŸŒ **Live API**

```
https://eco-vision-1.onrender.com
```

Swagger UI:

```
https://eco-vision-1.onrender.com/docs
```

Upload an image here to see detections, confidences, reuse tips, and annotated output.

---

# ğŸ“ **Project Structure**

This is the complete structure of your `fastapi/` backend folder:

```
fastapi/
â”‚
â”œâ”€â”€ .env
â”œâ”€â”€ build.sh
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ ML work/
â”‚   â”‚   best.pt
â”‚   â”‚   notebook.ipynb
â”‚   â”‚   yolo12n.pt
â”‚   â”‚   yolo12s.pt
â”‚   â”‚   test.jpg
â”‚   â”‚   test0.jpg
â”‚   â”‚   test1.jpg
â”‚   â”‚   test2.jpg
â”‚   â”‚   test3.jpg
â”‚   â”‚   test4.jpg
â”‚   â”‚   test5.jpg
â”‚   â”‚   test6.jpg
â”‚   â”‚   test7.jpeg
â”‚   â”‚   test13.jpg
â”‚   â”‚   test15.webp
â”‚   â”‚   test16.jpg
â”‚   â”‚   test17.jpg
â”‚   â”‚   test20.jpg
â”‚   â”‚   test23.jpg
â”‚   â”‚
â”‚   â””â”€â”€ dest/
â”‚       â”‚   data.yaml
â”‚       â”‚   notebook4e6102f5bd.log
â”‚       â”‚   yolo11n.pt
â”‚       â”‚   yolo12n.pt
â”‚       â”‚   yolo12s.pt
â”‚       â”‚
â”‚       â””â”€â”€ runs/
â”‚           â””â”€â”€ detect/
â”‚               â”œâ”€â”€ custom_yolo_training/
â”‚               â”‚   â”‚   args.yaml
â”‚               â”‚   â”‚   labels.jpg
â”‚               â”‚   â”‚   results.csv
â”‚               â”‚   â”‚   train_batch0.jpg
â”‚               â”‚   â”‚   train_batch1.jpg
â”‚               â”‚   â”‚   train_batch2.jpg
â”‚               â”‚   â”‚
â”‚               â”‚   â””â”€â”€ weights/
â”‚               â”‚           best.pt     â† FINAL TRAINED MODEL
â”‚               â”‚           last.pt
â”‚               â”‚
â”‚               â””â”€â”€ train/
â”‚                   â”‚   args.yaml
â”‚                   â”‚   labels.jpg
â”‚                   â”‚   results.csv
â”‚                   â”‚   results.png
â”‚                   â”‚   confusion_matrix.png
â”‚                   â”‚   confusion_matrix_normalized.png
â”‚                   â”‚   BoxF1_curve.png
â”‚                   â”‚   BoxPR_curve.png
â”‚                   â”‚   BoxP_curve.png
â”‚                   â”‚   BoxR_curve.png
â”‚                   â”‚   train_batch0.jpg
â”‚                   â”‚   train_batch1.jpg
â”‚                   â”‚   train_batch2.jpg
â”‚                   â”‚   val_batch0_labels.jpg
â”‚                   â”‚   val_batch0_pred.jpg
â”‚                   â”‚   val_batch1_labels.jpg
â”‚                   â”‚   val_batch1_pred.jpg
â”‚                   â”‚   val_batch2_labels.jpg
â”‚                   â”‚   val_batch2_pred.jpg
â”‚                   â”‚
â”‚                   â””â”€â”€ weights/
â”‚                           best.pt
â”‚                           last.pt
â”‚
â””â”€â”€ app/
    â”œâ”€â”€ data/
    â”‚   â””â”€â”€ reuse_mapping.json
    â”‚
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ yolo_detector.py
    â”‚
    â”œâ”€â”€ services/
    â”‚   â””â”€â”€ detection_service.py
    â”‚
    â”œâ”€â”€ main.py   â† FastAPI app entrypoint
    â”‚
    â””â”€â”€ weights/
        â””â”€â”€ best.pt   â† copied from ML work for production use
```

---

# ğŸ¤– **Custom YOLO Model**

Your final production model is:

```
ML work/dest/runs/detect/custom_yolo_training/weights/best.pt
```

This file is manually copied into:

```
app/weights/best.pt
```

and loaded using `.env`:

```
MODEL_PATH=app/weights/best.pt
```

The model has **30 custom classes** (Banana, Bottle, Light bulb, Plastic bag, Cake, Pasta, etc.).

---

# ğŸ§  **How the Backend Works**

### **1. YOLO Model Layer (`yolo_detector.py`)**

* Loads the YOLO model
* Detects only your 30 custom classes
* Returns:

  * class ID
  * class name
  * bounding box
  * confidence (raw + %)
* Draws bounding boxes + labels on the image

### **2. Detection Service (`detection_service.py`)**

* Runs detection
* Loads reuse tips from `reuse_mapping.json`
* Adds `"reuse_tip"` to each detected item
* Returns:

  * detections
  * annotated RGB image (for Base64 conversion)
  * total count

### **3. FastAPI Layer (`main.py`)**

Endpoints:

```
GET /health
POST /detect
```

`/detect`:

1. Accepts file upload
2. Saves it temporarily
3. Runs detection
4. Encodes annotated image to Base64
5. Returns JSON response
6. Deletes temp file

---

# ğŸ“¤ **API Usage**

## **POST /detect**

### Request:

Upload an image as `file`.

### Example (curl):

```bash
curl -X POST "https://eco-vision-1.onrender.com/detect" \
  -F "file=@test.jpg"
```

### Example Response:

```json
{
  "total_items": 2,
  "detections": [
    {
      "class_id": 15,
      "class_name": "Bottle",
      "confidence": { "score": 0.8731, "percent": 87.3 },
      "bbox": [140, 50, 310, 490],
      "reuse_tip": "Repurpose as a water bottle, planter, or storage container."
    }
  ],
  "annotated_image": "<BASE64_STRING>"
}
```

Render this in frontend:

```js
<img src={`data:image/jpeg;base64,${data.annotated_image}`} />
```

---

# ğŸ§ª **Testing the API**

You can test with the images located directly inside:

```
fastapi/ML work/
```

Or upload any custom picture through:

```
https://eco-vision-1.onrender.com/docs
```

---

# ğŸ³ **Deployment (Render)**

Your backend is deployed on Render at:

```
https://eco-vision-1.onrender.com
```

### Required Environment Variables (Render Dashboard):

```
MODEL_PATH=app/weights/best.pt
ALLOWED_ORIGINS=https://eco-vision-lzem.onrender.com
```

### Start Command (Render):

```
uvicorn app.main:app --host 0.0.0.0 --port $PORT
```

Render automatically injects `$PORT`.

### Build Command:

Handled by your Dockerfile.

---

# ğŸ” **Updating the YOLO Model**

To update the model after retraining:

1. Go to your training output:

   ```
   ML work/dest/runs/detect/custom_yolo_training/weights/best.pt
   ```

2. Copy the updated best.pt to:

   ```
   app/weights/best.pt
   ```

3. Redeploy or restart the FastAPI server.

---

# ğŸ¯ **Purpose of This Backend**

This service provides:

* Real-time recognition of recyclable or reusable items
* Sustainability-oriented suggestions
* Visual annotations
* A clean JSON API for frontend or mobile apps

It is the **AI engine** behind the Eco Vision project.

---

# ğŸ‘¤ **Author**

**Shivansh Gupta**
Creator of Eco Vision â€” ML + backend + deployment.

---
